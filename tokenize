#!/data/EM/venv3.9/bin/python

import os
import argparse
from numpy import array, uint32
import shelve

import sentencepiece as spm

parser = argparse.ArgumentParser()
parser.add_argument("corpus", nargs="?", type=str, help="The name of the corpus to tokenize. ids will be output to <corpus>/corpus.tok or <corpus>/train.tok if the -t flag is given.", default = None)
parser.add_argument("-s", "--string", type=str, help="A string to tokenize. Output will go to stdout.", default = None)
parser.add_argument("-t", "--trainingcorpus", action="store_true", help="Tokenize traning corpus called train. Tokens will be output to <corpus>/train.tok.")
parser.add_argument("-m", "--modelfile", type=str, help="Model file to use. Default = large.model", default="large.model")
parser.add_argument("-v", "--verbose", action="store_true", help="Display verbose output")
args = parser.parse_args()

sp = spm.SentencePieceProcessor(model_file=args.modelfile)
if args.verbose: print (f"Using sentence piece model file {args.modelfile}")

def lines(filename, frm, to):
    with open(filename, "r") as f:
        f.seek(frm)
        if frm != 0:
            f.readline()
        while f.tell() < to:
            line = f.readline()
            if line == "":
                break
            yield(line)

def lenFile(filename):
    with open(filename, "r") as f:
        f.seek(0, os.SEEK_END)
        return (f.tell())

if args.string:
    print (sp.encode(args.string, out_type=str))
    print (sp.encode(args.string))
else:
    if args.trainingcorpus:
        corpus = args.corpus+"/train"
    else:
        corpus = args.corpus+"/corpus"

    fileLength = lenFile(corpus)
    step = int(fileLength/80)
    toks = []
    n = 0
    for i in range(0, fileLength, step):
        for line in lines(corpus, i, i+step):
            ids = sp.encode(line)
            toks.extend(ids)
            n += 1
            if n % 10000 == 0:
                print (f"{n} lines done.", flush = True)
    allids = array(toks, uint32)
    allids.tofile(corpus+".tok")
    if args.verbose: print (f"Output tokens to file {corpus+'.tok'}")

params = shelve.open(f"{args.corpus}/params")
params["sentencepiece model"] = args.modelfile
params.close()
